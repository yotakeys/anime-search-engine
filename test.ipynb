{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KEY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import  pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import  faiss\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/processed.csv', sep='/')\n",
    "model = SentenceTransformer('model/')\n",
    "index = faiss.read_index('animes.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to return top_k anime dictionary based query\n",
    "\n",
    "def fetch_anime(dataframe_idx):\n",
    "    info = data.iloc[dataframe_idx]\n",
    "    meta = dict()\n",
    "    meta['title'] = info['title']\n",
    "    return meta\n",
    "    \n",
    "def search(query, top_k, index, model):\n",
    "    query_vector = model.encode([query])\n",
    "    top_k = index.search(query_vector, top_k)\n",
    "    result_id = top_k[1].tolist()[0]\n",
    "    result_id = list(np.unique(result_id))\n",
    "    results =  [fetch_anime(idx) for idx in result_id]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\t {'title': 'Yakitate!! Japan'}\n",
      "\t {'title': 'Bakuretsu Tenshi'}\n",
      "\t {'title': 'Ben-To'}\n",
      "\t {'title': 'Koufuku Graffiti'}\n",
      "\t {'title': 'Shokugeki no Souma'}\n",
      "\t {'title': 'Pan de Peace!'}\n",
      "\t {'title': 'Amaama to Inazuma'}\n",
      "\t {'title': 'Isekai Shokudou'}\n",
      "\t {'title': 'Ramen Daisuki Koizumi-san'}\n",
      "\t {'title': 'Emiya-san Chi no Kyou no Gohan'}\n"
     ]
    }
   ],
   "source": [
    "query=\"Anime about food and cooking\"\n",
    "results=search(query, top_k=10, index=index, model=model)\n",
    "print(\"\\n\")\n",
    "for result in results:\n",
    "    print('\\t',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = pd.read_csv('dataset/raw/reviews.csv')\n",
    "anime_data = pd.read_csv('dataset/raw/animes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 108246 entries, 0 to 158139\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   uid       108246 non-null  int64  \n",
      " 1   title     108246 non-null  object \n",
      " 2   synopsis  108246 non-null  object \n",
      " 3   genre     108246 non-null  object \n",
      " 4   aired     108246 non-null  object \n",
      " 5   episodes  108246 non-null  float64\n",
      " 6   score     108246 non-null  float64\n",
      " 7   review    108246 non-null  object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 7.4+ MB\n"
     ]
    }
   ],
   "source": [
    "selected_reviews = review_data[['anime_uid', 'text']].groupby(by=['anime_uid']).count().sort_values('text', ascending=False)\n",
    "selected_reviews = selected_reviews[selected_reviews.text > 15].reset_index()\n",
    "\n",
    "# Adding all reviews/sum up all reviews from the same anime\n",
    "\n",
    "reviews_joined = review_data[['anime_uid', 'text']][review_data['anime_uid'].isin(selected_reviews['anime_uid'])]\n",
    "\n",
    "anime_data = anime_data.drop_duplicates(subset=['uid'])\n",
    "reviews_joined.rename(columns={'anime_uid' : 'uid', 'text' : 'review'}, inplace=True)\n",
    "animes_reviews = pd.merge(anime_data, reviews_joined, how='right', on=['uid']).drop_duplicates()\n",
    "\n",
    "# we will only take columns that we think have the potential to be used as descriptions\n",
    "\n",
    "animes_reviews = animes_reviews.drop(['members', 'popularity', 'ranked', 'img_url', 'link'],axis=1)\n",
    "animes_reviews = animes_reviews.dropna()\n",
    "animes_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def preProcessReview(row):\n",
    "    res = str(row['review'])\n",
    "    \n",
    "    while '\\n' in res or '\\r' in res or \"\\'\" in res or '  ' in res:\n",
    "        res = res.replace('\\n','')\n",
    "        res = res.replace('\\r','')\n",
    "        res = res.replace(\"\\'\",'')\n",
    "        res = res.replace('  ',' ')\n",
    "    \n",
    "    return res\n",
    "\n",
    "def preProcessScore(row):\n",
    "    res = str(row['score'])\n",
    "    \n",
    "    return 'Score ' + res\n",
    "\n",
    "def preProcessEpisodes(row):\n",
    "    res = str(row['episodes'])\n",
    "    res = res.replace(\".0\",'')\n",
    "    \n",
    "    return 'with ' + res + ' Episodes'\n",
    "\n",
    "def preProcessGenre(row):\n",
    "    res = row['genre']\n",
    "    res = res.replace(\"'\",'')\n",
    "    res = res.replace('[','')\n",
    "    res = res.replace(']','')\n",
    "    \n",
    "    return 'Genre ' + res\n",
    "\n",
    "def preProcessSynopsis(row):\n",
    "    res = str(row['synopsis'])\n",
    "    while '\\n' in res or '\\r' in res or \"\\'\" in res or '  ' in res:\n",
    "        res = res.replace('\\n','')\n",
    "        res = res.replace('\\r','')\n",
    "        res = res.replace(\"\\'\",'')\n",
    "        res = res.replace('  ',' ')\n",
    "        \n",
    "    return 'Synopsis, ' + res\n",
    "\n",
    "animes_reviews['synopsis'] = animes_reviews.apply(preProcessSynopsis, axis=1)\n",
    "animes_reviews['genre'] = animes_reviews.apply(preProcessGenre, axis=1)\n",
    "animes_reviews['episodes'] = animes_reviews.apply(preProcessEpisodes, axis=1)\n",
    "animes_reviews['score'] = animes_reviews.apply(preProcessScore, axis=1)\n",
    "animes_reviews['review'] = animes_reviews.apply(preProcessReview, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformText(row):\n",
    "    name = str(row['title']) + ' '\n",
    "    episodes = str(row['episodes']) + ' episode ' \n",
    "    tags = str(row['genre']) + ' '\n",
    "    year = str(row['aired']) + ' '\n",
    "    desc = str(row['synopsis']) + ' '\n",
    "    score = str(row['score']) + ' '\n",
    "    review = str(row['review']) + ' '\n",
    "    \n",
    "    num_features = [2,3]\n",
    "    features = [episodes, tags, year, desc, score, review]\n",
    "    \n",
    "    selected = random.sample(features, random.sample(num_features, 1)[0])\n",
    "    \n",
    "    res = str()\n",
    "    for text in selected:\n",
    "        res = res + text\n",
    "    \n",
    "    return res\n",
    "\n",
    "test = pd.DataFrame(columns=['title','text'])\n",
    "copi = animes_reviews.copy()\n",
    "test['text'] = copi.apply(transformText, axis=1)\n",
    "test['title'] = animes_reviews['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Results in Total Time: 536.6562509536743\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "sample = 1000\n",
    "import time\n",
    "t = time.time()\n",
    "for ind in test.sample(sample).index:\n",
    "    results=search(test['text'].loc[ind], top_k=3, index=index, model=model)\n",
    "    \n",
    "    for result in results:\n",
    "        if test['title'].loc[ind] == result['title']:\n",
    "            acc+=1\n",
    "            break\n",
    "\n",
    "print('>>>> Results in Total Time: {}'.format(time.time()-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.4\n"
     ]
    }
   ],
   "source": [
    "print(acc/sample * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66a084010f0746c76ec2284bd94410552a129f4a248954eb4fb49e45d1aa9635"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
